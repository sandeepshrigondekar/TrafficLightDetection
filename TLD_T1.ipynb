{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TLD_T1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMaJ4gA5RoPJTbYV+/TYC63",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepshrigondekar/TrafficLightDetection/blob/main/TLD_T1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmfSJWjKkZWc"
      },
      "source": [
        "# Mount Google Drive and initial few checks about the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFZurjoJ3S3j",
        "outputId": "106cbab4-c381-4fbe-d0dc-261b62694f3c"
      },
      "source": [
        "# This cell imports the drive library and mounts your Google Drive as a VM local drive. You can access to your Drive files \r\n",
        "# using this path \"/content/gdrive/My Drive/\"\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HKJZw2B3vG0",
        "outputId": "f30e6769-e086-48f3-f703-7b0f65e95ba2"
      },
      "source": [
        "# List the content of the google drive folder \r\n",
        "!ls -la \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 150830\n",
            "-rw------- 1 root root      6918 Aug 24  2014  210814EC02008317.pdf\n",
            "-rw------- 1 root root    265568 Nov 19 17:53  Automation.pptx\n",
            "drwx------ 2 root root      4096 Jan  2 12:46  Bosch_Dataset\n",
            "-rw------- 1 root root     91081 Oct 11  2014  CAS_31082014_32371670.pdf\n",
            "drwx------ 2 root root      4096 Jan 27  2020 'Colab Notebooks'\n",
            "-rw------- 1 root root 150828752 Jun 21  2020  creditcard.csv\n",
            "-rw------- 1 root root   3177781 Jul 14  2020  Docs.zip\n",
            "-rw------- 1 root root     18723 Sep  6  2014 'ELITE I20.XLS'\n",
            "-rw------- 1 root root       151 Mar  7  2010 'General Information all tours[1].gdoc'\n",
            "-rw------- 1 root root     19670 Dec 15 03:46  GYM-Data.xlsx\n",
            "drwx------ 2 root root      4096 Jul 28  2019  IITB-DS-ML\n",
            "drwx------ 2 root root      4096 Jan  2 12:46  .ipynb_checkpoints\n",
            "drwx------ 2 root root      4096 Sep  1 22:56  LJMU-MS\n",
            "drwx------ 2 root root      4096 Jan  7 17:28  MyLib\n",
            "-rw------- 1 root root      3748 Jan  6 17:06 'Notes from Implementation.txt'\n",
            "drwx------ 2 root root      4096 Sep  1 22:59  Personal\n",
            "drwx------ 2 root root      4096 Jan  4 11:27  TLD\n",
            "-rw------- 1 root root      1664 Jan 17 12:02  ToDo.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1px-rYHXkOeU"
      },
      "source": [
        "# Check Colab Environment Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4dRhakm3wBR",
        "outputId": "bc14b794-992c-4361-cbb7-bc2372b03811"
      },
      "source": [
        "# CUDA: Let's check that Nvidia CUDA is already pre-installed and which version is it. In some time from now maybe you \r\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "zOtvjkM734pA",
        "outputId": "8d0a4db1-efa3-4b78-9a3e-3b36283a0030"
      },
      "source": [
        "import tensorflow as tf; \r\n",
        "print(\"Tensorflow version is -->\",tf.__version__)\r\n",
        "!python --version\r\n",
        "#To make sure Colab uses GPU you can run\r\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version is --> 2.4.0\n",
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyVLPgdCjvH0",
        "outputId": "77551a42-3a59-4c53-d675-3a3087c58784"
      },
      "source": [
        "#To make sure that the current GPU memory utilization is 0\r\n",
        "# memory footprint support libraries/code\r\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\r\n",
        "gpu = GPUs[0]\r\n",
        "def printm():\r\n",
        " process = psutil.Process(os.getpid())\r\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "printm() "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=d03e6a271e3afdcdfe9acc37c192bb475430e58166e8c42d8600b7d55cd74396\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.2 GB  | Proc size: 1.1 GB\n",
            "GPU RAM Free: 14852MB | Used: 227MB | Util   2% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbAMxT154bxR",
        "outputId": "0d64aacd-70cf-4480-b79a-413f12ee9658"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im2Rk_xQ4Oil"
      },
      "source": [
        "# Project Setup\r\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHWnQoAp4mny",
        "outputId": "d715b11c-dde3-4691-e43c-0b01fac84730"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/TLD/darknet"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TLD/darknet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DyixeB6rItF"
      },
      "source": [
        "#Setup YOLO\r\n",
        "# !git clone https://github.com/ultralytics/yolov5  # clone repo"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzGJfiXE4JB8",
        "outputId": "2578b599-8795-4abe-a90f-f3ceddd71ef1"
      },
      "source": [
        "%cd yolov5\r\n",
        "%pip install -qr requirements.txt  # install dependencies\r\n",
        "\r\n",
        "import torch\r\n",
        "from IPython.display import Image, clear_output  # to display images\r\n",
        "\r\n",
        "#clear_output()\r\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TLD/darknet/yolov5\n",
            "\u001b[K     |████████████████████████████████| 645kB 8.6MB/s \n",
            "\u001b[?25hSetup complete. Using torch 1.7.0+cu101 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15079MB, multi_processor_count=40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpeocCcVSKth",
        "outputId": "3617ba01-cbf0-45c0-b70b-2b35e71bf4d4"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TLD/darknet/yolov5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RotzxUr-54mQ",
        "outputId": "b7d3950e-55f4-4aa9-9054-39a480fddbe5"
      },
      "source": [
        "# Run this mkdir only once\r\n",
        "# !mkdir training \r\n",
        "%cd training"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TLD/darknet/yolov5/training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pad4qPCbS50O"
      },
      "source": [
        "# !find /content/gdrive/MyDrive/Bosch_Dataset/dataset_train_rgb/rgb/train/ -type f -print0 | xargs -0 --no-run-if-empty cp --target-directory=/content/gdrive/MyDrive/TLD/darknet/yolov5/training/dataset/"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eK6lRuYszsg"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/TLD/darknet/yolov5/training/dataset/\r\n",
        "!ls *.png | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvS_1OwNUeUe"
      },
      "source": [
        "# !find /content/gdrive/MyDrive/Bosch_Dataset/dataset_train_rgb/traffic_light_labels_train/ -type f -print0 | xargs -0 --no-run-if-empty cp --target-directory=/content/gdrive/MyDrive/TLD/darknet/yolov5/training/dataset/"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxWlfgcDswCM"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/TLD/darknet/yolov5/training/dataset/\r\n",
        "!ls *.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS8a_BLyVz0o",
        "outputId": "955de2c7-e4a7-4b62-b8a9-de74492c0cbd"
      },
      "source": [
        "# Run only once\r\n",
        "# %cd /content/gdrive/MyDrive/TLD/darknet/yolov5/training\r\n",
        "# !python /content/gdrive/MyDrive/TLD/darknet/yolov5/training/split_dataset.py"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/TLD/darknet/yolov5/training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jkK2BjTu9ys",
        "outputId": "923686d9-b118-48cc-919b-756cac8201b4"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/TLD/darknet/yolov5/training/data/images/train\r\n",
        "!ls *.png | wc -l"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/TLD/darknet/yolov5/training/data/images/train\n",
            "4055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StmjmT9IwfeU",
        "outputId": "ea3e656f-b883-4d8e-ebc9-c5046db3e89d"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/TLD/darknet/yolov5/training/data/images/valid\r\n",
        "!ls *.png | wc -l"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/TLD/darknet/yolov5/training/data/images/valid\n",
            "1038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-GnZyjew2nV",
        "outputId": "11fb19cf-933d-4aed-fb88-eab986a4dd47"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/TLD/darknet/yolov5/training/data/labels/train\r\n",
        "!ls *.txt | wc -l"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/TLD/darknet/yolov5/training/data/labels/train\n",
            "4055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYgIVuNiw7Dr",
        "outputId": "f0203ea0-1658-422f-acbb-922b3f47b582"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/TLD/darknet/yolov5/training/data/labels/valid\r\n",
        "!ls *.txt | wc -l"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/TLD/darknet/yolov5/training/data/labels/valid\n",
            "1038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5xbewhdByB6"
      },
      "source": [
        "# %load_ext tensorboard\r\n",
        "# %tensorboard --logdir runs/train"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAVT6tnj_wzI",
        "outputId": "01e5d372-dae2-486d-b463-387661645826"
      },
      "source": [
        "%pip install -q wandb  \r\n",
        "!wandb login --relogin"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2JbBE12xfSz",
        "outputId": "69cd8e28-d7a3-406e-a1eb-f049dee1d770"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/TLD/darknet/yolov5"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/TLD/darknet/yolov5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZkPXVgkxmJ-"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc5n68XrCExf",
        "outputId": "196a1b44-954c-4520-eded-290dc7ac45cf"
      },
      "source": [
        "# Train YOLOv5s on custom dataset for 3 epochs\r\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data training/dataset.yaml --cfg training/yolov5l.yaml --weights yolov5s.pt --nosave --cache "
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 v4.0-40-g2fc4760 torch 1.7.0+cu101 CUDA:0 (Tesla T4, 15079.75MB)\n",
            "\n",
            "Namespace(adam=False, batch_size=16, bucket='', cache_images=True, cfg='training/yolov5l.yaml', data='training/dataset.yaml', device='', epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', single_cls=False, sync_bn=False, total_batch_size=16, weights='yolov5s.pt', workers=8, world_size=1)\n",
            "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
            "2021-01-23 19:50:33.546724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  1   1611264  models.common.C3                        [256, 256, 9]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  1   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n",
            "  9                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     70005  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 499 layers, 46669045 parameters, 46669045 gradients, 114.4 GFLOPS\n",
            "\n",
            "Transferred 59/650 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 110 .bias, 110 conv.weight, 107 other\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mssand\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2021-01-23 19:50:49.366744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.14\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ssand/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ssand/YOLOv5/runs/2b4ice5p\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/gdrive/My Drive/TLD/darknet/yolov5/wandb/run-20210123_195048-2b4ice5p\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train' for images and labels... 82 found, 0 missing, 39 empty, 1 corrupted:   2%|▏         | 82/4055 [00:45<35:57,  1.84it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label training/data/images/train/108372.png: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train' for images and labels... 2310 found, 0 missing, 926 empty, 2 corrupted:  57%|█████▋    | 2310/4055 [20:04<14:11,  2.05it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train' for images and labels... 3400 found, 0 missing, 1321 empty, 3 corrupted:  84%|████████▍ | 3400/4055 [29:08<04:53,  2.23it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train' for images and labels... 3411 found, 0 missing, 1321 empty, 4 corrupted:  84%|████████▍ | 3411/4055 [29:14<05:26,  1.97it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label training/data/images/train/677570.png: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train' for images and labels... 3639 found, 0 missing, 1428 empty, 5 corrupted:  90%|████████▉ | 3639/4055 [31:11<03:10,  2.19it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label training/data/images/train/704716.png: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train' for images and labels... 3723 found, 0 missing, 1460 empty, 6 corrupted:  92%|█████████▏| 3723/4055 [31:52<02:47,  1.99it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label training/data/images/train/712210.png: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train' for images and labels... 4055 found, 0 missing, 1567 empty, 6 corrupted: 100%|██████████| 4055/4055 [34:46<00:00,  1.94it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: training/data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train.cache' for images and labels... 4055 found, 0 missing, 1567 empty, 6 corrupted: 100%|██████████| 4055/4055 [00:00<00:00, 5520254.05it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.8GB): 100%|██████████| 4049/4049 [02:33<00:00, 26.36it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'training/data/labels/valid' for images and labels... 247 found, 0 missing, 86 empty, 1 corrupted:  24%|██▍       | 247/1038 [02:03<06:51,  1.92it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label training/data/images/valid/27234.png: negative labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'training/data/labels/valid' for images and labels... 404 found, 0 missing, 156 empty, 2 corrupted:  39%|███▉      | 404/1038 [03:18<05:11,  2.04it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label training/data/images/valid/482112.png: negative labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'training/data/labels/valid' for images and labels... 1038 found, 0 missing, 374 empty, 2 corrupted: 100%|██████████| 1038/1038 [08:15<00:00,  2.10it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: training/data/labels/valid.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'training/data/labels/valid.cache' for images and labels... 1038 found, 0 missing, 374 empty, 2 corrupted: 100%|██████████| 1038/1038 [00:00<00:00, 5668864.00it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB): 100%|██████████| 1036/1036 [00:22<00:00, 46.78it/s]\n",
            "Plotting labels... \n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 1.81, Best Possible Recall (BPR) = 0.8391. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 2200 of 8478 labels are < 3 pixels in size.\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 8467 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.73 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.455/0.855-mean/best, past_thr=0.554-mean: 2,4,  3,7,  4,10,  6,13,  7,17,  10,21,  13,27,  17,36,  29,60\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8589: 100%|██████████| 1000/1000 [00:02<00:00, 350.48it/s]\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.83 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.462/0.858-mean/best, past_thr=0.556-mean: 2,5,  3,6,  4,9,  5,12,  7,15,  9,20,  12,27,  17,35,  27,56\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "       0/2     8.57G    0.1519   0.01273    0.0517    0.2164         2       640: 100%|██████████| 254/254 [03:03<00:00,  1.39it/s]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 65/65 [00:14<00:00,  4.49it/s]\n",
            "                 all    1.04e+03    2.21e+03           0           0    2.04e-08    4.05e-09\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "       1/2     9.29G    0.1436   0.01005   0.04349    0.1971         3       640: 100%|██████████| 254/254 [02:59<00:00,  1.42it/s]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 65/65 [00:11<00:00,  5.46it/s]\n",
            "                 all    1.04e+03    2.21e+03           0           0     0.00479     0.00128\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "       2/2      9.3G    0.1281   0.01274   0.03947    0.1803         2       640: 100%|██████████| 254/254 [03:02<00:00,  1.39it/s]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 65/65 [00:16<00:00,  3.92it/s]\n",
            "                 all    1.04e+03    2.21e+03      0.0186      0.0877      0.0148     0.00278\n",
            "             RedLeft    1.04e+03         233      0.0319       0.124      0.0129     0.00259\n",
            "                 Red    1.04e+03         669      0.0603      0.0837      0.0158     0.00262\n",
            "            RedRight    1.04e+03           1           0           0           0           0\n",
            "           GreenLeft    1.04e+03          35           0           0     0.00636     0.00118\n",
            "               Green    1.04e+03    1.03e+03      0.0566       0.494      0.0821      0.0156\n",
            "          GreenRight    1.04e+03           2           0           0           0           0\n",
            "              Yellow    1.04e+03          94           0           0    8.14e-05    1.49e-05\n",
            "                 off    1.04e+03         151           0           0    0.000966    0.000193\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 93.8MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 93.8MB\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "3 epochs completed in 0.166 hours.\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 21690\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/gdrive/My Drive/TLD/darknet/yolov5/wandb/run-20210123_195048-2b4ice5p/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/gdrive/My Drive/TLD/darknet/yolov5/wandb/run-20210123_195048-2b4ice5p/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step 43\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime 3368\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp 1611434816\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.1281\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.01274\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.03947\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.01861\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.08773\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.01477\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.00278\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.11633\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.03801\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00304\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00304\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.02694\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime ▁▁▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆██████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp ▁▁▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆██████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▆▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss █▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▃█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▄█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▆▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss ▁▃█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁█▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁█▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 46 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mexp\u001b[0m: \u001b[34mhttps://wandb.ai/ssand/YOLOv5/runs/2b4ice5p\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GD5KZoy7j0o",
        "outputId": "94f55605-65fb-4e96-9674-2386fcb51484"
      },
      "source": [
        "# Train yolov5l on custom dataset for 300 epochs\r\n",
        "!python train.py --img 640 --batch 64 --epochs 300 --data training/dataset.yaml --cfg training/yolov5l.yaml --weights yolov5l.pt --nosave --cache "
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 2, done.\u001b[K\n",
            "remote: Counting objects:  50% (1/2)\u001b[K\rremote: Counting objects: 100% (2/2)\u001b[K\rremote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 2 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  50% (1/2)   \rUnpacking objects: 100% (2/2)   \rUnpacking objects: 100% (2/2), done.\n",
            "From https://github.com/ultralytics/yolov5\n",
            "   2fc4760..9a3da79  master     -> origin/master\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 1 commit. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
            "YOLOv5 v4.0-40-g2fc4760 torch 1.7.0+cu101 CUDA:0 (Tesla T4, 15079.75MB)\n",
            "\n",
            "Namespace(adam=False, batch_size=64, bucket='', cache_images=True, cfg='training/yolov5l.yaml', data='training/dataset.yaml', device='', epochs=300, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp3', single_cls=False, sync_bn=False, total_batch_size=64, weights='yolov5l.pt', workers=8, world_size=1)\n",
            "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
            "2021-01-23 20:56:19.553710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  1   1611264  models.common.C3                        [256, 256, 9]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  1   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n",
            "  9                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     70005  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 499 layers, 46669045 parameters, 46669045 gradients, 114.4 GFLOPS\n",
            "\n",
            "Transferred 642/650 items from yolov5l.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 110 .bias, 110 conv.weight, 107 other\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mssand\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2021-01-23 20:56:31.786453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.14\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ssand/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ssand/YOLOv5/runs/c5oeu8je\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/gdrive/My Drive/TLD/darknet/yolov5/wandb/run-20210123_205630-c5oeu8je\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train.cache' for images and labels... 4055 found, 0 missing, 1567 empty, 6 corrupted: 100%|██████████| 4055/4055 [00:00<00:00, 21420532.39it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.8GB): 100%|██████████| 4049/4049 [02:33<00:00, 26.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'training/data/labels/valid.cache' for images and labels... 1038 found, 0 missing, 374 empty, 2 corrupted: 100%|██████████| 1038/1038 [00:00<00:00, 678567.26it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB): 100%|██████████| 1036/1036 [00:40<00:00, 25.88it/s]\n",
            "Plotting labels... \n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 1.81, Best Possible Recall (BPR) = 0.8391. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 2200 of 8478 labels are < 3 pixels in size.\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 8467 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.73 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.455/0.855-mean/best, past_thr=0.554-mean: 2,4,  3,7,  4,10,  6,13,  7,17,  10,21,  13,27,  17,36,  29,60\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8589: 100%|██████████| 1000/1000 [00:02<00:00, 344.15it/s]\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.83 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.462/0.858-mean/best, past_thr=0.556-mean: 2,5,  3,6,  4,9,  5,12,  7,15,  9,20,  12,27,  17,35,  27,56\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp3\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "  0%|          | 0/64 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"train.py\", line 522, in <module>\n",
            "    train(hyp, opt, device, tb_writer, wandb)\n",
            "  File \"train.py\", line 289, in train\n",
            "    pred = model(imgs)  # forward\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/TLD/darknet/yolov5/models/yolo.py\", line 119, in forward\n",
            "    return self.forward_once(x, profile)  # single-scale inference, train\n",
            "  File \"/content/gdrive/MyDrive/TLD/darknet/yolov5/models/yolo.py\", line 135, in forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/TLD/darknet/yolov5/models/common.py\", line 87, in forward\n",
            "    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 117, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/TLD/darknet/yolov5/models/common.py\", line 53, in forward\n",
            "    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/TLD/darknet/yolov5/models/common.py\", line 37, in forward\n",
            "    return self.act(self.bn(self.conv(x)))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 423, in forward\n",
            "    return self._conv_forward(input, self.weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 420, in _conv_forward\n",
            "    self.padding, self.dilation, self.groups)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 14.73 GiB total capacity; 13.27 GiB already allocated; 64.88 MiB free; 13.41 GiB reserved in total by PyTorch)\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 22890\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/gdrive/My Drive/TLD/darknet/yolov5/wandb/run-20210123_205630-c5oeu8je/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/gdrive/My Drive/TLD/darknet/yolov5/wandb/run-20210123_205630-c5oeu8je/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime 205\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp 1611435595\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mexp3\u001b[0m: \u001b[34mhttps://wandb.ai/ssand/YOLOv5/runs/c5oeu8je\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b37U2qN1DS33",
        "outputId": "7895152c-613c-4c23-99d1-5f2c76755378"
      },
      "source": [
        "# Train yolov5l on custom dataset for 300 epochs\r\n",
        "!python train.py --img 640 --batch 16 --epochs 300 --data training/dataset.yaml --cfg training/yolov5l.yaml --weights yolov5l.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 1 commit. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
            "YOLOv5 v4.0-40-g2fc4760 torch 1.7.0+cu101 CUDA:0 (Tesla T4, 15079.75MB)\n",
            "\n",
            "Namespace(adam=False, batch_size=16, bucket='', cache_images=True, cfg='training/yolov5l.yaml', data='training/dataset.yaml', device='', epochs=300, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp4', single_cls=False, sync_bn=False, total_batch_size=16, weights='yolov5l.pt', workers=8, world_size=1)\n",
            "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
            "2021-01-23 21:02:32.731697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  1   1611264  models.common.C3                        [256, 256, 9]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  1   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n",
            "  9                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     70005  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 499 layers, 46669045 parameters, 46669045 gradients, 114.4 GFLOPS\n",
            "\n",
            "Transferred 642/650 items from yolov5l.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 110 .bias, 110 conv.weight, 107 other\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mssand\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2021-01-23 21:02:45.393403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.14\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ssand/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ssand/YOLOv5/runs/15vv85pp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/gdrive/My Drive/TLD/darknet/yolov5/wandb/run-20210123_210243-15vv85pp\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'training/data/labels/train.cache' for images and labels... 4055 found, 0 missing, 1567 empty, 6 corrupted: 100%|██████████| 4055/4055 [00:00<00:00, 9365585.20it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.8GB): 100%|██████████| 4049/4049 [02:33<00:00, 26.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'training/data/labels/valid.cache' for images and labels... 1038 found, 0 missing, 374 empty, 2 corrupted: 100%|██████████| 1038/1038 [00:00<00:00, 599598.89it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB): 100%|██████████| 1036/1036 [00:39<00:00, 26.12it/s]\n",
            "Plotting labels... \n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 1.81, Best Possible Recall (BPR) = 0.8391. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 2200 of 8478 labels are < 3 pixels in size.\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 8467 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.73 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.455/0.855-mean/best, past_thr=0.554-mean: 2,4,  3,7,  4,10,  6,13,  7,17,  10,21,  13,27,  17,36,  29,60\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8589: 100%|██████████| 1000/1000 [00:02<00:00, 352.63it/s]\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.83 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.462/0.858-mean/best, past_thr=0.556-mean: 2,5,  3,6,  4,9,  5,12,  7,15,  9,20,  12,27,  17,35,  27,56\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp4\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "     0/299     9.41G    0.1245    0.0179   0.04498    0.1874        62       640:  87%|████████▋ | 221/254 [02:41<00:23,  1.41it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mjA7nWlAMKD"
      },
      "source": [
        "# Train yolov5s on custom dataset for 300 epochs\r\n",
        "!python train.py --img 640 --batch 16 --epochs 300 --data training/dataset.yaml --cfg training/yolov5s.yaml --weights yolov5s.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUP5XoWj8LZS"
      },
      "source": [
        "# Train yolov5x on custom dataset for 300 epochs\r\n",
        "!python train.py --img 640 --batch 16 --epochs 300 --data training/dataset.yaml --cfg training/yolov5x.yaml --weights yolov5x.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEpshnFuCjO-"
      },
      "source": [
        "# Train yolov5m on custom dataset for 300 epochs\r\n",
        "!python train.py --img 640 --batch 16 --epochs 300 --data training/dataset.yaml --cfg training/yolov5m.yaml --weights yolov5m.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK4Her0GD7xR"
      },
      "source": [
        "# !python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images/\r\n",
        "# Image(filename='runs/detect/exp/zidane.jpg', width=600)\r\n",
        "\r\n",
        "# !python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source /content/gdrive/MyDrive/Bosch_Dataset/dataset_train_rgb/traffic_light_images_train/\r\n",
        "# Image(filename='/content/gdrive/MyDrive/Bosch_Dataset/dataset_train_rgb/traffic_light_images_train/237868.png', width=600)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}